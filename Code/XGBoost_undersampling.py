#This is TfIdf + SVD + XGBoost with undersampling

#python imports
import numpy as np
import codecs
import nltk
from nltk.corpus import stopwords
from os import listdir
import random
import scipy
import h5py

#keras imports
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten
from keras.layers import LSTM, Flatten
from keras.preprocessing.text import one_hot
from keras.preprocessing.sequence import pad_sequences
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence
from keras.models import model_from_json


#scikit-learn imports
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import f1_score
from sklearn.utils import class_weight
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import f1_score, precision_score, recall_score

#xgboost imports
from xgboost import XGBClassifier


def train_and_predict(X, Y):
	np.random.seed(7)
	top_words = 5000
	max_review_length = 150
	
	X_train = X[:3000]
	X_test = X[3000:]
	Y_train = Y[:3000]
	Y_test = Y[3000:]

	#Convert training text into tfidf features
	count_vect = CountVectorizer()
	X_train_counts = count_vect.fit_transform(X_train)
	tf_transformer = TfidfTransformer()
	X_train_tf = tf_transformer.fit_transform(X_train_counts)
	Y_train = np.array(Y_train)

	#Perform dimensionality reduction using svd
	svd = TruncatedSVD(n_components = 100, n_iter=7, random_state=50)
	X_train_tf = scipy.sparse.csc_matrix(X_train_tf)
	X_train_svd = svd.fit_transform(X_train_tf)

	#Train XGBoost
	model = XGBClassifier()
	model.fit(X_train_svd, Y_train)

	#Convert test text into features
	X_test_counts = count_vect.transform(X_test)
	X_test_tf = tf_transformer.transform(X_test_counts)

	#Perform dimensionality reduction using svd on test
	X_test_tf = svd.transform(X_test_tf)

	#Predict the final values
	Y_pred = model.predict(X_test_tf)
	predictions = [round(value) for value in Y_pred]
	
	#Print the F Score, Precision and Recall
	print("F Score: %.2f%%" % (f1_score(Y_test, predictions) * 100.0))
	print('Precision Score: %.2f%%' % (precision_score(Y_test, predictions) * 100.0))
	print('Recall Score: %.2f%%' % (recall_score(Y_test, predictions) * 100.0))

#Take input folder and return dataset with labels
def generateData(dataFolder):
	stops = set(stopwords.words("english"))  
	X = []
	Y = []
	sentence = ''
	relevance = 0
	for fileName in listdir(dataFolder):
		f = codecs.open(dataFolder + fileName, encoding='utf-8')
		for line in f:
			if '\n' in line and len(line) == 2: #End of a Sentence
				if sentence != '':
					X.append(sentence)
					Y.append(relevance)
				#Reset sentence and relevance for next line
				sentence = ''
				relevance = 0 
			else:	#Same sentence still being continued
				token = line.split(' ')[0].lower()
				#Keep only words of letters and not stop words
				if token not in stops and token not in ",!.:<>":
					if sentence == '': 
						sentence = token
					else: 
						sentence += ' ' + token
				if line[:-1].split(' ')[-1] != 'O': #if it is annotated, then it is relevant 
					relevance = 1

	return X,Y

#Get the training data
X, Y = generateData("training_material/data/tokenized/")

#Find number of positives and negatives in the dataset and make it balanced
pos = []
neg = []
i = 0
for i in range(0, len(X)):
        if Y[i] == 1:
                pos.append((X[i], Y[i]))
        else:
                neg.append((X[i], Y[i]))
print (len(pos))
print (len(neg))

data = random.sample(pos, 2000)
data = data + random.sample(neg, 2000)
random.shuffle(data)

train = data[:3000]
test = data[3000:]
X_train = []
Y_train = []
X_test = []
Y_test = []
for each in train:
        X_train.append(each[0])
        Y_train.append(each[1])


for each in test:
        X_test.append(each[0])
        Y_test.append(each[1])

train_and_predict(X_train + X_test, Y_train + Y_test)
